<!-- TOC -->

- [第一章 MySQL架构与历史](#第一章-mysql架构与历史)
    - [1、MySQL的存储引擎架构](#1mysql的存储引擎架构)
    - [2、MySQL的逻辑架构](#2mysql的逻辑架构)
        - [2.1 组成部分：](#21-组成部分)
        - [2.2 查询的过程：](#22-查询的过程)
    - [3.事务：事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。【事务内的语句要么全部执行成功，要么全部执行失败】](#3事务事务指的是满足-acid-特性的一组操作可以通过-commit-提交一个事务也可以使用-rollback-进行回滚事务内的语句要么全部执行成功要么全部执行失败)
        - [3.1 ACID](#31-acid)
            - [1. 原子性（Atomicity）：一个事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。](#1-原子性atomicity一个事务被视为不可分割的最小单元事务的所有操作要么全部提交成功要么全部失败回滚)
            - [2. 一致性（Consistency）：一致性保证应用程序只能看到初始一致性状态和最终的一致性状态，而不能看见中间状态。](#2-一致性consistency一致性保证应用程序只能看到初始一致性状态和最终的一致性状态而不能看见中间状态)
            - [3. 隔离性（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的。具有四种隔离级别：](#3-隔离性isolation一个事务所做的修改在最终提交以前对其它事务是不可见的具有四种隔离级别)
                - [1） 未提交读（READ UNCOMMITTED）：事务中的修改，即使没有提交，对其它事务也是可见的【存在：脏读、不可重复读、幻影读】。](#1-未提交读read-uncommitted事务中的修改即使没有提交对其它事务也是可见的存在脏读不可重复读幻影读)
                - [2） 提交读（不可重复度）（READ COMMITTED）：一个事务所做的修改在提交之前对其它事务是不可见的。【存在：不可重复读、幻影读】【是除了MySQL外大多数其他数据库默认的隔离级别】](#2-提交读不可重复度read-committed一个事务所做的修改在提交之前对其它事务是不可见的存在不可重复读幻影读是除了mysql外大多数其他数据库默认的隔离级别)
                - [3） 可重复读（REPEATABLE READ）：保证在同一个事务中多次读取同样数据的结果是一样的。【存在：幻读】【MySQL默认的隔离级别】【应用：银行统计存款】](#3-可重复读repeatable-read保证在同一个事务中多次读取同样数据的结果是一样的存在幻读mysql默认的隔离级别应用银行统计存款)
                - [4） 可串行化（SERIALIZABLE）：强制事务串行执行。](#4-可串行化serializable强制事务串行执行)
            - [4. 持久性（Durability）：一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能会失。](#4-持久性durability一旦事务提交则其所做的修改将会永远保存到数据库中即使系统发生崩溃事务执行的结果也不能会失)
        - [3.2 并发一致性问题：产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁和多版本机制来实现，但是需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。](#32-并发一致性问题产生并发不一致性问题主要原因是破坏了事务的隔离性解决方法是通过并发控制来保证隔离性并发控制可以通过封锁和多版本机制来实现但是需要用户自己控制相当复杂数据库管理系统提供了事务的隔离级别让用户以一种更轻松的方式处理并发一致性问题)
            - [1） 丢失修改：T<sub>1</sub> 和 T<sub>2</sub> 两个事务都对一个数据进行修改，T<sub>1</sub> 先修改，T<sub>2</sub> 随后修改，T<sub>2</sub> 的修改覆盖了 T<sub>1</sub> 的修改。](#1-丢失修改tsub1sub-和-tsub2sub-两个事务都对一个数据进行修改tsub1sub-先修改tsub2sub-随后修改tsub2sub-的修改覆盖了-tsub1sub-的修改)
            - [2) 脏读：T<sub>1</sub> 修改一个数据，T<sub>2</sub> 随后读取这个数据。如果 T<sub>1</sub> 撤销了这次修改，那么 T<sub>2</sub> 读取的数据是脏数据。](#2-脏读tsub1sub-修改一个数据tsub2sub-随后读取这个数据如果-tsub1sub-撤销了这次修改那么-tsub2sub-读取的数据是脏数据)
            - [3) 不可重复读：T<sub>2</sub> 读取一个数据，T<sub>1</sub> 对该数据做了修改。如果 T<sub>2</sub> 再次读取这个数据，此时读取的结果和第一次读取的结果不同。【不可重复读是指A事务读取了B事务已经提交的更改数据】](#3-不可重复读tsub2sub-读取一个数据tsub1sub-对该数据做了修改如果-tsub2sub-再次读取这个数据此时读取的结果和第一次读取的结果不同不可重复读是指a事务读取了b事务已经提交的更改数据)
            - [4) 幻影读：T<sub>1</sub> 读取某个范围的数据，T<sub>2</sub> 在这个范围内插入新的数据，T<sub>1</sub> 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。](#4-幻影读tsub1sub-读取某个范围的数据tsub2sub-在这个范围内插入新的数据tsub1sub-再次读取这个范围的数据此时读取的结果和和第一次读取的结果不同)
    - [4、通过并发控制来保证隔离性，并发控制机制主要有两种：锁和多版本并发控制](#4通过并发控制来保证隔离性并发控制机制主要有两种锁和多版本并发控制)
        - [4.1 封锁：通过封锁实现并发控制来保证隔离性](#41-封锁通过封锁实现并发控制来保证隔离性)
            - [4.1.1 封锁粒度：MySQL 中提供了两种封锁粒度：行级锁以及表级锁。【在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡【锁策略？】。】](#411-封锁粒度mysql-中提供了两种封锁粒度行级锁以及表级锁在选择封锁粒度时需要在锁开销和并发程度之间做一个权衡锁策略)
            - [4.2 封锁类型](#42-封锁类型)
                - [1. 读写锁：包含读锁和写锁。又叫共享锁和排他锁](#1-读写锁包含读锁和写锁又叫共享锁和排他锁)
                - [2. 意向锁【？不懂】](#2-意向锁不懂)
            - [4.3 封锁协议](#43-封锁协议)
                - [1. 三级封锁协议](#1-三级封锁协议)
                    - [1.1 一级封锁协议：修改数据要加X锁【解决丢失修改问题，因为两个事务不能同时对一个数据进行修改，就不会存在覆盖】](#11-一级封锁协议修改数据要加x锁解决丢失修改问题因为两个事务不能同时对一个数据进行修改就不会存在覆盖)
                    - [1.2 二级封锁协议：在一级的基础上，读取数据必须加 S 锁。【解决脏读问题，因为S与X不能共存，所以你在写的时候，我是不能读的】](#12-二级封锁协议在一级的基础上读取数据必须加-s-锁解决脏读问题因为s与x不能共存所以你在写的时候我是不能读的)
                    - [1.3 三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。【解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变】](#13-三级封锁协议在二级的基础上要求读取数据-a-时必须加-s-锁直到事务结束了才能释放-s-锁解决不可重复读的问题因为读-a-时其它事务不能对-a-加-x-锁从而避免了在读的期间数据发生改变)
                - [2. 两段锁协议：InnoDB采用的是两段锁协议。整个事务分为两个阶段，前一个阶段为加锁，后一个阶段为解锁【事务遵循两段锁协议是保证可串行化调度的充分条件】。](#2-两段锁协议innodb采用的是两段锁协议整个事务分为两个阶段前一个阶段为加锁后一个阶段为解锁事务遵循两段锁协议是保证可串行化调度的充分条件)
                - [3、MySQL 隐式与显示锁定：MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。](#3mysql-隐式与显示锁定mysql-的-innodb-存储引擎采用两段锁协议会根据隔离级别在需要的时候自动加锁并且所有的锁都是在同一时刻被释放这被称为隐式锁定)
        - [4.2 多版本并发控制（Multi-Version Concurrency Control, MVCC）:是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别【不能解决幻读】](#42-多版本并发控制multi-version-concurrency-control-mvcc是-mysql-的-innodb-存储引擎实现隔离级别的一种具体方式用于实现提交读和可重复读这两种隔离级别不能解决幻读)
            - [1、InnoDB 的 MVCC 是通过在每行记录后面保存两个隐藏的列来实现：行的创建版本号和删除版本号 【保存数据在某个时间的快照】](#1innodb-的-mvcc-是通过在每行记录后面保存两个隐藏的列来实现行的创建版本号和删除版本号-保存数据在某个时间的快照)
            - [2、Undo 日志：MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。](#2undo-日志mvcc-使用到的快照存储在-undo-日志中该日志通过回滚指针把一个数据行record的所有快照连接起来)
            - [3、可重复读隔离级别的实现过程](#3可重复读隔离级别的实现过程)
                - [1）. SELECT](#1-select)
                - [2）. INSERT](#2-insert)
                - [3）. DELETE](#3-delete)
                - [4）. UPDATE](#4-update)
            - [4、 幻读的解决：【在可重复读隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。】](#4-幻读的解决在可重复读隔离级别下使用-mvcc--next-key-locks-可以解决幻读问题)
                - [1）. 快照读：使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。【快照读的时候，用的是MVCC解决的幻读】](#1-快照读使用-mvcc-读取的是快照中的数据这样可以减少加锁所带来的开销快照读的时候用的是mvcc解决的幻读)
                - [2）. 当前读：读取的是最新的数据，需要加锁。【使用的是 Next-Key Locks（InnoDB 的一种锁实现） 解决的幻读】](#2-当前读读取的是最新的数据需要加锁使用的是-next-key-locksinnodb-的一种锁实现-解决的幻读)
                    - [2.1 Next-Key Locks：它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。](#21-next-key-locks它是-record-locks-和-gap-locks-的结合不仅锁定一个记录上的索引也锁定索引之间的间隙)
                    - [# 2.2.1 Record Locks（行锁？）：锁定一个记录上的索引，而不是记录本身。](#-221-record-locks行锁锁定一个记录上的索引而不是记录本身)
                    - [# 2.2.2 Gap Locks（间隙锁）：锁定索引之间的间隙，但是不包含索引本身。](#-222-gap-locks间隙锁锁定索引之间的间隙但是不包含索引本身)
    - [5、MyISAM 和 InnoDB](#5myisam-和-innodb)
- [二、索引（“键”）：索引是存储引擎用于快速找到记录的一种数据结构。索引是对记录按照一个或者多个字段进行排序的一种方式，对列表中的某个字段建立索引会创建另一种数据结构，其中保存着字段的值，每个值又指向与它相关的记录。](#二索引键索引是存储引擎用于快速找到记录的一种数据结构索引是对记录按照一个或者多个字段进行排序的一种方式对列表中的某个字段建立索引会创建另一种数据结构其中保存着字段的值每个值又指向与它相关的记录)
    - [2.1 索引类型](#21-索引类型)
        - [前言） B- Tree 索引原理](#前言-b--tree-索引原理)
            - [1. B+树（平衡多路查找树）的特点：](#1-b树平衡多路查找树的特点)
            - [2. 存储引擎使用不同的方式使用B-树索引，各有优劣](#2-存储引擎使用不同的方式使用b-树索引各有优劣)
            - [3. 操作](#3-操作)
            - [4. 与红黑树的比较](#4-与红黑树的比较)
        - [1）. B+Tree 索引](#1-btree-索引)
            - [1.1 是大多数 MySQL 存储引擎的默认索引类型。](#11-是大多数-mysql-存储引擎的默认索引类型)
            - [1.2 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。](#12-因为不再需要进行全表扫描只需要对树进行搜索即可所以查找速度快很多)
            - [1.3 除了用于查找，还可以用于排序和分组。](#13-除了用于查找还可以用于排序和分组)
            - [1.4 可以指定多个列作为索引列，多个索引列共同组成键。但存在限制](#14-可以指定多个列作为索引列多个索引列共同组成键但存在限制)
                - [限制：B+ 树索引适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。](#限制b-树索引适用于全键值键值范围和键前缀查找其中键前缀查找只适用于最左前缀查找如果不是按照索引列的顺序进行查找则无法使用索引)
            - [1.5 InnoDB 的 B+Tree 索引分为主索引和辅助索引。](#15-innodb-的-btree-索引分为主索引和辅助索引)
                - [1.5.1 主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。](#151-主索引的叶子节点-data-域记录着完整的数据记录这种索引方式被称为聚簇索引因为无法把数据行存放在两个不同的地方所以一个表只能有一个聚簇索引)
                - [1.5.2 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。](#152-辅助索引的叶子节点的-data-域记录着主键的值因此在使用辅助索引进行查找时需要先查找到主键值然后再到主索引中进行查找)
            - [1.6 附录：聚簇索引：并不是一种索引类型，而是一种数据存储方式](#16-附录聚簇索引并不是一种索引类型而是一种数据存储方式)
        - [2. 哈希索引：【用的hash表，先使用索引列的全部内容来计算哈希值，然后用该值寻找对应的记录的指针】](#2-哈希索引用的hash表先使用索引列的全部内容来计算哈希值然后用该值寻找对应的记录的指针)
            - [2.1 哈希索引的优缺点：哈希索引能以 O(1) 时间进行查找，但是失去了有序性：](#21-哈希索引的优缺点哈希索引能以-o1-时间进行查找但是失去了有序性)
                - [1）无法用于排序与分组；](#1无法用于排序与分组)
                - [2）只支持精确查找，无法用于部分查找和范围查找。](#2只支持精确查找无法用于部分查找和范围查找)
            - [2.2 自适应哈希索引：InnoDB 存储引擎的一个特殊的功能。，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。](#22-自适应哈希索引innodb-存储引擎的一个特殊的功能当某个索引值被使用的非常频繁时会在-btree-索引之上再创建一个哈希索引这样就让-btree-索引具有哈希索引的一些优点比如快速的哈希查找)
            - [2.3 自定义哈希索引：在B+树基础上创建一个伪哈希索引，它还是使用B+树进行查找，但使用的是哈希值而不是键本身进行索引查找。【应用：当需要存大量URL的时候，此时只需要根据哈希值做快速的整数比较就能找到索引条目，而用URL值比较会很慢](#23-自定义哈希索引在b树基础上创建一个伪哈希索引它还是使用b树进行查找但使用的是哈希值而不是键本身进行索引查找应用当需要存大量url的时候此时只需要根据哈希值做快速的整数比较就能找到索引条目而用url值比较会很慢)
        - [3. 全文索引：MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。](#3-全文索引myisam-存储引擎支持全文索引用于查找文本中的关键词而不是直接比较是否相等)
        - [4. 空间数据索引](#4-空间数据索引)
    - [2.2 索引的优点：](#22-索引的优点)
        - [1）大大减少了服务器需要扫描的数据行数](#1大大减少了服务器需要扫描的数据行数)
        - [2）帮助服务器避免进行排序和创建临时表（B+树索引是有序的，可以用来做ORDER BY 和GROUP BY操作）](#2帮助服务器避免进行排序和创建临时表b树索引是有序的可以用来做order-by-和group-by操作)
        - [3）将随机I/O变为顺序I/O（B+树索引是有序的，也就是相邻的数据都存储在一起了）](#3将随机io变为顺序iob树索引是有序的也就是相邻的数据都存储在一起了)
    - [2.3 MySQL有两种方式可以生成有序的结果：通过排序操作、通过索引顺序扫描【 explain 出来的 type 为 “index” 表示按索引顺序扫描】](#23-mysql有两种方式可以生成有序的结果通过排序操作通过索引顺序扫描-explain-出来的-type-为-index-表示按索引顺序扫描)
    - [2.4 索引优化](#24-索引优化)
        - [1. 多列索引：在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。](#1-多列索引在需要使用多个列作为条件进行查询时使用多列索引比使用多个单列索引性能更好)
        - [2. 索引列的顺序：让选择性最强的索引列放在前面。](#2-索引列的顺序让选择性最强的索引列放在前面)
        - [3. 前缀索引：对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。](#3-前缀索引对于-blobtext-和-varchar-类型的列必须使用前缀索引只索引开始的部分字符)
        - [4.使用覆盖索引：索引包含所有需要查询的字段的值。](#4使用覆盖索引索引包含所有需要查询的字段的值)
            - [4.1 覆盖查询的优点：](#41-覆盖查询的优点)
                - [1）索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。](#1索引通常远小于数据行的大小只读取索引能大大减少数据访问量)
                - [2）一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。](#2一些存储引擎例如-myisam在内存中只缓存索引而数据依赖于操作系统来缓存因此只访问索引可以不使用系统调用通常比较费时)
                - [3）对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。](#3对于-innodb-引擎若辅助索引能够覆盖查询则无需访问主索引)
                - [4）因为索引是按照列值顺序存储的（至少在单个页内是如此），所以对于I/O密集型的范围查询会比随机从磁盘读取一行数据的I/O要少得多。](#4因为索引是按照列值顺序存储的至少在单个页内是如此所以对于io密集型的范围查询会比随机从磁盘读取一行数据的io要少得多)
    - [2.5 注意：](#25-注意)
        - [1） 独立的列：在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。](#1-独立的列在进行查询时索引列不能是表达式的一部分也不能是函数的参数否则无法使用索引)
        - [2）在InnoDB 表中按主键顺序插入行：如果正在使用InnoDB 表并且没有什么数据需要聚集，那么可以定义一个AUTO_INCREAMENT自增列作为主键，这样可以保证数据行是按顺序插入的。](#2在innodb-表中按主键顺序插入行如果正在使用innodb-表并且没有什么数据需要聚集那么可以定义一个auto_increament自增列作为主键这样可以保证数据行是按顺序插入的)
- [三、查询性能优化【要合理设计查询，查询优化、索引优化、库表结构优化需要齐头并进】](#三查询性能优化要合理设计查询查询优化索引优化库表结构优化需要齐头并进)
    - [3.1 使用 Explain 进行分析：开发人员可以通过分析 Explain 结果来优化查询语句。](#31-使用-explain-进行分析开发人员可以通过分析-explain-结果来优化查询语句)
    - [3.2 优化数据访问](#32-优化数据访问)
        - [1. 减少请求的数据量：【让查询只返回需要的数据】](#1-减少请求的数据量让查询只返回需要的数据)
            - [1.1 只返回必要的列【最好不要使用 SELECT * 语句。】](#11-只返回必要的列最好不要使用-select--语句)
            - [1.2 只返回必要的行【使用 LIMIT 语句来限制返回的数据。】](#12-只返回必要的行使用-limit-语句来限制返回的数据)
            - [1.3 缓存重复查询的数据](#13-缓存重复查询的数据)
        - [2. 减少服务器端扫描的行数](#2-减少服务器端扫描的行数)
            - [2.1 最有效的方式是使用索引来覆盖查询。](#21-最有效的方式是使用索引来覆盖查询)
            - [2.2 重写这个复杂的查询](#22-重写这个复杂的查询)
    - [3.3 重构查询方式](#33-重构查询方式)
        - [1. 切分大查询：一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。](#1-切分大查询一个大查询如果一次性执行的话可能一次锁住很多数据占满整个事务日志耗尽系统资源阻塞很多小的但重要的查询)
        - [2. 分解关联查询：将一个关联查询（join）分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：](#2-分解关联查询将一个关联查询join分解成对每一个表进行一次单表查询然后在应用程序中进行关联这样做的好处有)
- [四、切分：【分表：把一张表按照一定的规则分解成不同的实体表】](#四切分分表把一张表按照一定的规则分解成不同的实体表)
    - [4.1 水平切分：又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。](#41-水平切分又称为-sharding它是将同一个表中的记录拆分到多个结构相同的表中)
        - [4.1.1  Sharding 策略](#411--sharding-策略)
            - [1) 哈希取模：hash(key) 模 N；](#1-哈希取模hashkey-模-n)
            - [2) 范围：可以是 ID 范围也可以是时间范围；](#2-范围可以是-id-范围也可以是时间范围)
            - [3) 映射表：使用单独的一个数据库来存储映射关系。](#3-映射表使用单独的一个数据库来存储映射关系)
        - [4.1.2 Sharding 存在的问题](#412-sharding-存在的问题)
            - [1). 事务问题（分片事务一致性难以解决）：使用分布式事务来解决，比如 XA 接口。](#1-事务问题分片事务一致性难以解决使用分布式事务来解决比如-xa-接口)
            - [2). JOIN问题【跨界点JOIN性能差，逻辑复杂】：可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。](#2-join问题跨界点join性能差逻辑复杂可以将原来的连接分解成多个单表查询然后在用户程序中进行连接)
            - [3）. ID 唯一性问题：](#3-id-唯一性问题)
                - [3.1 使用全局唯一 ID（GUID）](#31-使用全局唯一-idguid)
                - [3.2 为每个分片指定一个 ID 范围](#32-为每个分片指定一个-id-范围)
                - [3.3 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)](#33-分布式-id-生成器-如-twitter-的-snowflake-算法)
    - [垂直切分：是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。](#垂直切分是将一张表按列切分成多个表通常是按照列的关系密集程度进行切分也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中)
- [五、复制：MySQL支持两种复制方式：基于行的复制和基于语句的复制（逻辑复制）](#五复制mysql支持两种复制方式基于行的复制和基于语句的复制逻辑复制)
    - [5.1 复制解决的基本问题是让一台服务器的数据和其他服务器保持同步：一台主库的数据可以同步到多台备库上。](#51-复制解决的基本问题是让一台服务器的数据和其他服务器保持同步一台主库的数据可以同步到多台备库上)
    - [5.2 什么是主从复制：主从复制是用来建立一个和主数据库完全一样的数据库环境，成为从数据库；主数据库一般是准实时的业务数据库。](#52-什么是主从复制主从复制是用来建立一个和主数据库完全一样的数据库环境成为从数据库主数据库一般是准实时的业务数据库)
    - [5.3 主从复制主要涉及三个线程：：binlog 线程、I/O 线程和 SQL 线程。](#53-主从复制主要涉及三个线程binlog-线程io-线程和-sql-线程)
        - [步骤一：主库db的更新事件(update、insert、delete)被写到binlog【二进制日志】](#步骤一主库db的更新事件updateinsertdelete被写到binlog二进制日志)
        - [步骤二：从库发起连接，连接到主库](#步骤二从库发起连接连接到主库)
        - [步骤三：此时主库创建一个binlog dump 线程，把binlog的内容发送到从库](#步骤三此时主库创建一个binlog-dump-线程把binlog的内容发送到从库)
        - [步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log【重做日志】.](#步骤四从库启动之后创建一个io线程读取主库传过来的binlog内容并写入到relay-log重做日志)
        - [步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db.](#步骤五还会创建一个sql线程从relay-log里面读取内容从exec_master_log_pos位置开始执行读取到的更新事件将更新内容写入到slave的db)
    - [5.3 主从复制的好处：](#53-主从复制的好处)
        - [1）作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作。](#1作为后备数据库主数据库服务器故障后可切换到从数据库继续工作)
        - [2) 架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能](#2-架构的扩展业务量越来越大io访问频率过高单机无法满足此时做多库的存储降低磁盘io访问的频率提高单个机器的io性能)
        - [3）读写分离：主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。](#3读写分离主服务器处理写操作以及实时性要求比较高的读操作而从服务器处理读操作)
- [六、数据类型](#六数据类型)
    - [6.1 整型：NT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。](#61-整型nt11-中的数字只是规定了交互工具显示字符的个数对于存储和计算来说是没有意义的)
    - [6.2 浮点数：DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。](#62-浮点数decimal18-9-表示总共-18-位取-9-位存储小数部分剩下-9-位存储整数部分)
    - [6.3 字符串：主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。](#63-字符串主要有-char-和-varchar-两种类型一种是定长的一种是变长的)
    - [6.4 时间和日期：DATETIME 和 TIMESTAMP。](#64-时间和日期datetime-和-timestamp)
        - [1. DATETIME：能够保存从 1001 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。【它与时区无关。】](#1-datetime能够保存从-1001-年到-9999-年的日期和时间精度为秒使用-8-字节的存储空间它与时区无关)
        - [2. TIMESTAMP：和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。【它和时区有关】](#2-timestamp和-unix-时间戳相同保存从-1970-年-1-月-1-日午夜格林威治时间以来的秒数使用-4-个字节只能表示从-1970-年到-2038-年它和时区有关)
- [七、视图](#七视图)
    - [1、视图本身是一个虚拟表，在创建的瞬间，便确定了结构（每次查询视图，实际还是去查询原来的表）](#1视图本身是一个虚拟表在创建的瞬间便确定了结构每次查询视图实际还是去查询原来的表)
    - [2、视图的算法（Algotithm）有三种：](#2视图的算法algotithm有三种)
        - [2.1 undefined：【默认方式】，由MySQL判断使用哪种算法](#21-undefined默认方式由mysql判断使用哪种算法)
        - [2.2 merge：【合并算法】，每当执行的时候，先将视图的sql语句于外部查询视图的sql语句合并在一起最终执行。](#22-merge合并算法每当执行的时候先将视图的sql语句于外部查询视图的sql语句合并在一起最终执行)
        - [2.3 temptable：【临时表算法】，每当查询的时候，将视图的sql语句生成一个结果的临时表，再在临时表内进行查询](#23-temptable临时表算法每当查询的时候将视图的sql语句生成一个结果的临时表再在临时表内进行查询)
    - [3、注意：如果视图包含group by、distinct、任何聚合函数、union、子查询等，只要无法在原表记录和视图记录建立一一映射的场景中，MySQL都将使用临时表算法来实现视图](#3注意如果视图包含group-bydistinct任何聚合函数union子查询等只要无法在原表记录和视图记录建立一一映射的场景中mysql都将使用临时表算法来实现视图)
- [八、外键约束](#八外键约束)
    - [1、InnoDB 是目前MySQL中唯一支持外键的内置存储引擎。](#1innodb-是目前mysql中唯一支持外键的内置存储引擎)
- [九、分布式（XA）事务](#九分布式xa事务)
    - [1、存储引擎的事务特性能保证在存储引擎级别实现ACID](#1存储引擎的事务特性能保证在存储引擎级别实现acid)
    - [2、而分布式事务让存储引擎级别的ACID 可以扩展到数据库层面（跨存储引擎的事务），甚至可以扩展到多个数据库应用之间。](#2而分布式事务让存储引擎级别的acid-可以扩展到数据库层面跨存储引擎的事务甚至可以扩展到多个数据库应用之间)
    - [3、XA 事务需要通过两个阶段的提交来实现：](#3xa-事务需要通过两个阶段的提交来实现)
        - [3.1 第一阶段：XA事务中需要有一个事务协调器来保证所有的事务参与者都完成了准备工作。](#31-第一阶段xa事务中需要有一个事务协调器来保证所有的事务参与者都完成了准备工作)
        - [3.2 第二阶段：如果协调者收到所有参与者都准备好的消息，就会告诉所有的事务可以提交了。](#32-第二阶段如果协调者收到所有参与者都准备好的消息就会告诉所有的事务可以提交了)
    - [4、XA 事务分为：](#4xa-事务分为)
        - [1）内部XA事务：MySQL本身的插件式架构导致其在内部需要使用XA事务](#1内部xa事务mysql本身的插件式架构导致其在内部需要使用xa事务)
        - [2）外部XA事务：MySQL可以参与到外部的分布式事务中](#2外部xa事务mysql可以参与到外部的分布式事务中)
- [十、分区表](#十分区表)
    - [1、分区表：是一个独立的逻辑表，底层由多个物理子表组成。](#1分区表是一个独立的逻辑表底层由多个物理子表组成)
    - [2、分区表的原理：所有底层表都必须使用相同的存储引擎，分区表的索引只是在各底层表上各自加上一个完全相同的索引](#2分区表的原理所有底层表都必须使用相同的存储引擎分区表的索引只是在各底层表上各自加上一个完全相同的索引)
    - [3、分区的类型](#3分区的类型)
        - [1）range分区：将数据划分为不同的范围。（连续）](#1range分区将数据划分为不同的范围连续)
        - [2）list分区：允许系统通过预定义的列表值来对数据进行分割（非连续，按值分区）](#2list分区允许系统通过预定义的列表值来对数据进行分割非连续按值分区)
        - [3）hash分区：主要用来确保数据在预先确定数目的分区中平均分布。](#3hash分区主要用来确保数据在预先确定数目的分区中平均分布)
        - [4）key分区：类似hash分区，只是hash分区使用的是用户自定义的表达式（hash）,而key分区使用的哈希函数是由MySQL服务器提供的。](#4key分区类似hash分区只是hash分区使用的是用户自定义的表达式hash而key分区使用的哈希函数是由mysql服务器提供的)
    - [4、优化查询：](#4优化查询)
        - [1）在查询时，要在where条件中代入分区列，即使看似多余也要带上，这样就可以让优化器能够过滤掉无需访问的分区](#1在查询时要在where条件中代入分区列即使看似多余也要带上这样就可以让优化器能够过滤掉无需访问的分区)
        - [2）如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会缓存在内存中，查询时只访问很小的一个分区表，能够有效地利用索引和缓存。](#2如果数据有明显的热点而且除了这部分数据其他数据很少被访问到那么可以将热点数据单独放在一个分区让这个分区的数据能够有机会缓存在内存中查询时只访问很小的一个分区表能够有效地利用索引和缓存)
    - [5、分区的优缺点：](#5分区的优缺点)
        - [5.1 分区的优点：](#51-分区的优点)
            - [1）可以让单表存储更多的数据](#1可以让单表存储更多的数据)
            - [2）分区表的数据更易维护，可以清除整个分区批量删除数据，还可以对一个独立分区进行优化、检查、修复等操作](#2分区表的数据更易维护可以清除整个分区批量删除数据还可以对一个独立分区进行优化检查修复等操作)
            - [3）部分查询能够从查询条件确定只落在少数分区上，速度会很快](#3部分查询能够从查询条件确定只落在少数分区上速度会很快)
            - [4）分区表的数据还可以分布在不同的物理设备上，从而高效利用多个硬件设备](#4分区表的数据还可以分布在不同的物理设备上从而高效利用多个硬件设备)
            - [5）可以备份和恢复整个分区](#5可以备份和恢复整个分区)
        - [5.2 分区的缺点：](#52-分区的缺点)
            - [1）一个表最多只能有1024个分区](#1一个表最多只能有1024个分区)
            - [2）如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来](#2如果分区字段中有主键或者唯一索引的列那么所有主键列和唯一索引列都必须包含进来)
            - [3）分区表中无法使用外键约束](#3分区表中无法使用外键约束)
- [十一、MySQL大表优化方案](#十一mysql大表优化方案)
    - [1）优化数据访问【前面】](#1优化数据访问前面)
    - [2）升级硬件：通过提升CPU和内存、使用ssd，都能显著提升MySQL的性能](#2升级硬件通过提升cpu和内存使用ssd都能显著提升mysql的性能)
    - [3）读写分离：主库用来处理写操作和实时性较高的读操作，从库用来处理写操作](#3读写分离主库用来处理写操作和实时性较高的读操作从库用来处理写操作)
    - [4）用缓存：使用MySQL的缓存，另外对重量级、更新少的数据考虑使用应用级别的缓存](#4用缓存使用mysql的缓存另外对重量级更新少的数据考虑使用应用级别的缓存)
    - [5）使用分区表：分区表是一个独立的逻辑表，底层由多个物理子表构成](#5使用分区表分区表是一个独立的逻辑表底层由多个物理子表构成)
        - [5.1 在查询时，要在where条件中代入分区列，即使看似多余也要带上，这样就可以让优化器能够过滤掉无需访问的分区](#51-在查询时要在where条件中代入分区列即使看似多余也要带上这样就可以让优化器能够过滤掉无需访问的分区)
        - [5.2 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会缓存在内存中，查询时只访问很小的一个分区](#52-如果数据有明显的热点而且除了这部分数据其他数据很少被访问到那么可以将热点数据单独放在一个分区让这个分区的数据能够有机会缓存在内存中查询时只访问很小的一个分区)
    - [6）进行分表：把一张表按照一定的规则分成不同的实体表](#6进行分表把一张表按照一定的规则分成不同的实体表)
        - [6.1 垂直拆分：将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以按经常使用和不经常使用来切分。](#61-垂直拆分将一张表按列切分成多个表通常是按照列的关系密集程度进行切分也可以按经常使用和不经常使用来切分)
            - [6.1.1 优点：](#611-优点)
                - [1）使行数据变小，一个数据块（页）能存放更多的数据，从而在查询时减少I/O次数](#1使行数据变小一个数据块页能存放更多的数据从而在查询时减少io次数)
                - [2）简化表结构，易于维护](#2简化表结构易于维护)
            - [6.1.2 缺点：](#612-缺点)
                - [1）主键出现冗余，需要管理冗余列](#1主键出现冗余需要管理冗余列)
                - [2）会引起join操作，可以通过在应用层进行join来减少服务器压力](#2会引起join操作可以通过在应用层进行join来减少服务器压力)
                - [3）事务变得更复杂，且还是存在单表数据量过大的问题（需要水平拆分）](#3事务变得更复杂且还是存在单表数据量过大的问题需要水平拆分)
        - [6.2 水平拆分：将用一个表中的记录拆分到多个结构相同的表中。当一个表中的数据不断增多时，水平拆分是必然的选择，它可以将数据分步到集群的不同节点上，从而缓解单个数据库的压力。](#62-水平拆分将用一个表中的记录拆分到多个结构相同的表中当一个表中的数据不断增多时水平拆分是必然的选择它可以将数据分步到集群的不同节点上从而缓解单个数据库的压力)
- [十二 杂](#十二-杂)
    - [1 死锁](#1-死锁)
        - [1.1 检测：InnoDB 存储引擎，能检测到死锁的循环依赖，并返回一个错误。](#11-检测innodb-存储引擎能检测到死锁的循环依赖并返回一个错误)
        - [1.2 死锁解决：InnoDB 处理死锁是将持有最少行级排他锁的事务进行回滚。](#12-死锁解决innodb-处理死锁是将持有最少行级排他锁的事务进行回滚)
    - [2 事务日志：可以提高事务的效率](#2-事务日志可以提高事务的效率)
        - [1）使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘](#1使用事务日志存储引擎在修改表的数据时只需要修改其内存拷贝再把该修改行为记录持久在硬盘上的事务日志中而不用每次都将修改的数据本身持久到磁盘)
        - [2）事务日志采用的是追加的方式，因此写日志的操作是磁盘上小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说快得多](#2事务日志采用的是追加的方式因此写日志的操作是磁盘上小块区域内的顺序io而不像随机io需要在磁盘的多个地方移动磁头所以采用事务日志的方式相对来说快得多)
        - [3）事务日志持久以后，内存中被修改的数据在后台可以慢慢刷回磁盘，也叫预写式日志，所以修改数据需要写两次磁盘。](#3事务日志持久以后内存中被修改的数据在后台可以慢慢刷回磁盘也叫预写式日志所以修改数据需要写两次磁盘)
    - [3 冗余索引和重复索引](#3-冗余索引和重复索引)
        - [3.1 重复索引：指在相同的列上按照相同的顺序创建相同类型的索引（发现后应该立即移除）](#31-重复索引指在相同的列上按照相同的顺序创建相同类型的索引发现后应该立即移除)
        - [3.2 冗余索引：通常发生在为表添加新索引的时候，如创建了索引（A,B），再创建索引（A）就是冗余索引，因为这只是前一个索引的前缀索引](#32-冗余索引通常发生在为表添加新索引的时候如创建了索引ab再创建索引a就是冗余索引因为这只是前一个索引的前缀索引)
        - [3.3 编写查询语句应该尽可能选择合适的索引以避免单行查找，尽可能使用数据原生顺序从而避免额外的排序操作。](#33-编写查询语句应该尽可能选择合适的索引以避免单行查找尽可能使用数据原生顺序从而避免额外的排序操作)
- [参考资料](#参考资料)

<!-- /TOC -->
# 第一章 MySQL架构与历史
## 1、MySQL的存储引擎架构
* MySQL最重要、最与众不同的特性是它的存储引擎架构，这种架构的设计将查询处理及其他系统任务和数据的存储/提取相分离。
    * 这种处理和存储分离的设计可以在使用时根据性能、特性、以及其他需求来选择数据存储方式。
## 2、MySQL的逻辑架构
![](http://www.kokojia.com/Public/images/upload/article/2016-07/5790bc78264b9.png)
![](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20180108/5b82030ffbf9455d8d40eb78f7dc9f2b.jpeg)
### 2.1 组成部分：
* 客户端请求来了，会进行连接和认证。
* 服务器层：核心功能包括查询解析、优化、缓存、以及所有的内置函数；所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。
* 存储引擎层：负责MySQL中数据的存储和读取
    * 服务器通过API和存储引擎进行通信，这些接口屏蔽了不同存储引擎之间的差异。存储引擎不会解析SQL，（但InooDB会解析外键，因为MySQL服务器没有实现该功能）
### 2.2 查询的过程：
* 1）客户端发送一条查询给服务器
* 2）服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段
* 3）服务器进行sql解析、预处理、再由优化器生成对应的执行计划。
* 4）MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询。
* 5）将结果返回给客户端。


## 3.事务：事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。【事务内的语句要么全部执行成功，要么全部执行失败】

![](https://github.com/CyC2018/CS-Notes/raw/master/pics/185b9c49-4c13-4241-a848-fbff85c03a64.png)
```sql
start transaction;
内容
commit；//提交或者 rollback 回滚撤销所有的修改
```
* 事务是在存储引擎实现的，MySQL服务器层不管理事务：
    * 如果在事务中混合使用了事务型和非事务型的表，正常提交的情况下没什么问题，但遇到事务要回滚时，非事务型的表上的变更无法撤销。事务最终的状态无法确定。
### 3.1 ACID

#### 1. 原子性（Atomicity）：一个事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。

* 回滚可以用回滚日志来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

#### 2. 一致性（Consistency）：一致性保证应用程序只能看到初始一致性状态和最终的一致性状态，而不能看见中间状态。

* 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。
* 原子性只保证事务整体成功，不保证别人看不见中间状态

#### 3. 隔离性（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的。具有四种隔离级别：
##### 1） 未提交读（READ UNCOMMITTED）：事务中的修改，即使没有提交，对其它事务也是可见的【存在：脏读、不可重复读、幻影读】。

##### 2） 提交读（不可重复度）（READ COMMITTED）：一个事务所做的修改在提交之前对其它事务是不可见的。【存在：不可重复读、幻影读】【是除了MySQL外大多数其他数据库默认的隔离级别】

##### 3） 可重复读（REPEATABLE READ）：保证在同一个事务中多次读取同样数据的结果是一样的。【存在：幻读】【MySQL默认的隔离级别】【应用：银行统计存款】

##### 4） 可串行化（SERIALIZABLE）：强制事务串行执行。

----

| 隔离级别 | 脏读 | 不可重复读 | 幻影读 | 加锁读 |
| :---: | :---: | :---:| :---: | :---: |
| 未提交读 | √ | √ | √ | × |
| 提交读 | × | √ | √ | × |
| 可重复读 | × | × | √ | × |
| 可串行化 | × | × | × | √ |


#### 4. 持久性（Durability）：一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能会失。

* 使用重做日志（redo日志）来保证持久性。

----

事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系：

- 只有满足一致性，事务的执行结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。
- 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对数据库崩溃的情况。
![](https://github.com/CyC2018/CS-Notes/raw/master/pics/6675d713-8b59-4067-ad16-fdd538d4bb43.png)


* MySQL 默认采用自动提交模式。也就是说，如果不显式使用`START TRANSACTION`语句来开始一个事务，那么每个查询都会被当做一个事务自动提交。可使用set autocommit=0 来禁用，从此就要显式提交或回滚。但Alter Table这些命令在执行前会强制commit提交当前的活动事务。

### 3.2 并发一致性问题：产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁和多版本机制来实现，但是需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。

#### 1） 丢失修改：T<sub>1</sub> 和 T<sub>2</sub> 两个事务都对一个数据进行修改，T<sub>1</sub> 先修改，T<sub>2</sub> 随后修改，T<sub>2</sub> 的修改覆盖了 T<sub>1</sub> 的修改。
![](https://github.com/CyC2018/CS-Notes/raw/master/pics/88ff46b3-028a-4dbb-a572-1f062b8b96d3.png)

#### 2) 脏读：T<sub>1</sub> 修改一个数据，T<sub>2</sub> 随后读取这个数据。如果 T<sub>1</sub> 撤销了这次修改，那么 T<sub>2</sub> 读取的数据是脏数据。
![](https://github.com/CyC2018/CS-Notes/raw/master/pics/dd782132-d830-4c55-9884-cfac0a541b8e.png)

#### 3) 不可重复读：T<sub>2</sub> 读取一个数据，T<sub>1</sub> 对该数据做了修改。如果 T<sub>2</sub> 再次读取这个数据，此时读取的结果和第一次读取的结果不同。【不可重复读是指A事务读取了B事务已经提交的更改数据】

![](https://github.com/CyC2018/CS-Notes/raw/master/pics/c8d18ca9-0b09-441a-9a0c-fb063630d708.png)

#### 4) 幻影读：T<sub>1</sub> 读取某个范围的数据，T<sub>2</sub> 在这个范围内插入新的数据，T<sub>1</sub> 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。

![](https://github.com/CyC2018/CS-Notes/raw/master/pics/72fe492e-f1cb-4cfc-92f8-412fb3ae6fec.png)


## 4、通过并发控制来保证隔离性，并发控制机制主要有两种：锁和多版本并发控制
### 4.1 封锁：通过封锁实现并发控制来保证隔离性
* 封锁是指事务A在对某个数据对象（例如表、记录等）操作之前，先向系统发出请求，对其加锁。【加锁】

#### 4.1.1 封锁粒度：MySQL 中提供了两种封锁粒度：行级锁以及表级锁。【在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡【锁策略？】。】

* 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。

* 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。

* 在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。
![](https://github.com/CyC2018/CS-Notes/raw/master/pics/1a851e90-0d5c-4d4f-ac54-34c20ecfb903.jpg)

#### 4.2 封锁类型

##### 1. 读写锁：包含读锁和写锁。又叫共享锁和排他锁
* 读锁：又叫共享锁（Shared，S锁），是共享的，相互不阻塞
* 写锁：又叫排他锁（Exclusive，X锁），是排他的，一个写锁会阻塞其他写锁和读锁


锁的兼容关系如下：

| - | X | S |
| :--: | :--: | :--: |
|X|×|×|
|S|×|√|
于是在给定的时间里，只有一个用户能执行写入，并防止其他用户读取正在写入的同一资源

##### 2. 意向锁【？不懂】

使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。

在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。

意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：

- 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；
- 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。

通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。

各种锁的兼容关系如下：

| - | X | IX | S | IS |
| :--: | :--: | :--: | :--: | :--: |
|X     |×    |×    |×   | ×|
|IX    |×    |√   |×   | √|
|S     |×    |×    |√  | √|
|IS    |×    |√  |√  | √|

解释如下：

- 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁；
- S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。

#### 4.3 封锁协议

##### 1. 三级封锁协议

###### 1.1 一级封锁协议：修改数据要加X锁【解决丢失修改问题，因为两个事务不能同时对一个数据进行修改，就不会存在覆盖】
* 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。

* 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。

| T<sub>1</sub> | T<sub>2</sub> |
| :--: | :--: |
| lock-x(A) | |
| read A=20 | |
| | lock-x(A) |
|  | wait |
| write A=19 |. |
| commit |. |
| unlock-x(A) |. |
| | obtain |
| | read A=19 |
| | write A=21 |
| | commit |
| | unlock-x(A)|

###### 1.2 二级封锁协议：在一级的基础上，读取数据必须加 S 锁。【解决脏读问题，因为S与X不能共存，所以你在写的时候，我是不能读的】
* 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。

* 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。

| T<sub>1</sub> | T<sub>2</sub> |
| :--: | :--: |
| lock-x(A) | |
| read A=20 | |
| write A=19 | |
| | lock-s(A) |
|  | wait |
| rollback | .|
| A=20 |. |
| unlock-x(A) |. |
| | obtain |
| | read A=20 |
| | unlock-s(A)|
| | commit |
###### 1.3 三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。【解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变】

* 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。

| T<sub>1</sub> | T<sub>2</sub> |
| :--: | :--: |
| lock-s(A) | |
| read A=20 | |
|  |lock-x(A) |
| | wait |
|  read A=20| . |
| commit | .|
| unlock-s(A) |. |
| | obtain |
| | read A=20 |
| | write A=19|
| | commit |
| | unlock-X(A)|

##### 2. 两段锁协议：InnoDB采用的是两段锁协议。整个事务分为两个阶段，前一个阶段为加锁，后一个阶段为解锁【事务遵循两段锁协议是保证可串行化调度的充分条件】。
* 在事务执行过程中，随时都可以执行锁定，锁只有在执行commit 或者 rollback的时候才会都释放，并且所有的锁都是同一时刻被释放。（隐式）

* 可串行化调度：是指通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。

* 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。

```html
lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B)
```

但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。

```html
lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C)
```

##### 3、MySQL 隐式与显示锁定：MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。

InnoDB 也可以使用特定的语句进行显示锁定：

```sql
SELECT ... LOCK In SHARE MODE;
SELECT ... FOR UPDATE;
```



### 4.2 多版本并发控制（Multi-Version Concurrency Control, MVCC）:是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别【不能解决幻读】
* 而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。
* 可以认为MVCC是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。


#### 1、InnoDB 的 MVCC 是通过在每行记录后面保存两个隐藏的列来实现：行的创建版本号和删除版本号 【保存数据在某个时间的快照】

*  创建版本号：指示创建一个数据行的快照时的系统版本号；
*  删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。

* 版本号

    - 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。（事务的ID）
    - 事务版本号：事务开始时的系统版本号

#### 2、Undo 日志：MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。

![](https://github.com/CyC2018/CS-Notes/raw/master/pics/e41405a8-7c05-4f70-8092-e961e28d3112.jpg)

#### 3、可重复读隔离级别的实现过程

* 当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。

##### 1）. SELECT

* 把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于等于 T 的版本号，因为如果大于T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。
* 除此之外，T 所要读取的数据行快照的删除版本号要么不存在要么必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。

* 多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。


##### 2）. INSERT

将当前系统版本号作为数据行快照的创建版本号。

##### 3）. DELETE

将当前系统版本号作为数据行快照的删除版本号。

##### 4）. UPDATE

将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。

#### 4、 幻读的解决：【在可重复读隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。】

##### 1）. 快照读：使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。【快照读的时候，用的是MVCC解决的幻读】
* MVCC实现了事务的隔离性，因为是快照读，别的事务进行添加等操作打上的id号不是早于当前事务的就不会被select。那么就解决了幻读

```sql
select * from table ...;
```

##### 2）. 当前读：读取的是最新的数据，需要加锁。【使用的是 Next-Key Locks（InnoDB 的一种锁实现） 解决的幻读】
* 以下第一个语句需要加 S 锁，其它都需要加 X 锁。

```sql
select * from table where ? lock in share mode;
select * from table where ? for update;
insert;
update;
delete;
```


###### 2.1 Next-Key Locks：它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。
* 例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：

```sql
(negative infinity, 10]
(10, 11]
(11, 13]
(13, 20]
(20, positive infinity)
```


####### 2.2.1 Record Locks（行锁？）：锁定一个记录上的索引，而不是记录本身。

* 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

####### 2.2.2 Gap Locks（间隙锁）：锁定索引之间的间隙，但是不包含索引本身。
* 例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。

```sql
SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;
```

## 5、MyISAM 和 InnoDB
* MyISAM 适合select 密集型表
* InnoDB 适合Insert和Update密集型表
* 5.1 InnoDB 的特点：
    * 1）支持行锁：采用MVCC 来支持高并发，其默认的级别是可重复读，并通过MVCC和next-key locks 防止幻读
    * 2）支持事务
    * 3）支持外键
    * 4）支持崩溃后的安全恢复（事务失败）
    * 5）5.6.4以后也支持全文索引
* 5.2 MyISAM 的特点：
    * 1）只支持表锁，不支持行锁
    * 2）支持全文索引和压缩表
    * 3）不支持外键、事务，和崩溃后的安全恢复（只可以手工或自动执行检查和修复操作）
    # 三、存储引擎
*  InnoDB

是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。

实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ 间隙锁（Next-Key Locking）防止幻影读。

主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。

内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

* MyISAM

设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

提供了大量的特性，包括压缩表、空间数据索引等。

不支持事务。

不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。

可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

* 比较

    - 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。

    - 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。

    - 外键：InnoDB 支持外键。

    - 备份：InnoDB 支持在线热备份。

    - 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。

    - 其它特性：MyISAM 支持压缩表和空间数据索引。


# 二、索引（“键”）：索引是存储引擎用于快速找到记录的一种数据结构。索引是对记录按照一个或者多个字段进行排序的一种方式，对列表中的某个字段建立索引会创建另一种数据结构，其中保存着字段的值，每个值又指向与它相关的记录。
* 索引对于良好的性能非常关键，索引优化应该是对查询优化最有效的手段了，能轻易将查询性能提升几个数量级。
* 索引的使用：MySQL先在索引上按值查找，然后返回所有包含该值的数据行。
* 索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要，因为MySQL只能高效地使用索引最左前缀列。
* 索引的实现：在MySQL中，索引是在存储引擎层而不是服务层实现的，所以不同存储引擎具有不同的索引类型和实现。
* 对于非常小的表，大部分情况下简单的全表扫描比建立索引更加高效；对于大到中型的表，索引就非常有效；但对于特大型表，建立和维护索引的代价将会随之增长，这种情况下，就需要用一种技术可以直接区分出需要查询的一组数据，而不是一条一条记录地匹配，例如可以使用分区技术。

## 2.1 索引类型

* 索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。

### 前言） B- Tree 索引原理

#### 1. B+树（平衡多路查找树）的特点：
* 1）数据只保存在叶子节点上，非叶子结点（索引节点）只保存索引信息。
    * 索引节点存储的只是一个flag，不保存实际数据
    * 索引节点指示该节点的左子树比这个flag小，右子树大于等于这个flag。
* 2）叶子结点按照数据升序排序进行链接（串起来），提高了区间查询的性能。

#### 2. 存储引擎使用不同的方式使用B-树索引，各有优劣
* MyISAM：使用前缀压缩技术使索引更小，通过数据的物理位置引用被索引的行。
* InnoDB：按照原数据格式进行存储，根据主键引用被索引的行。

#### 3. 操作

* 进行查找操作时：
    * 1、首先在根节点进行二分查找，找到一个 key 所在的指针，
    * 2、然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，
    * 3、然后在叶子节点上进行二分查找，找出 key 所对应的 data。

* 插入删除操作会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。

#### 4. 与红黑树的比较

* 红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：

    * （一）更少的查找次数：B+ 树比红黑树矮的多，所以查找次数更少
        * 平衡树查找操作的时间复杂度等于树高 h，而树高大致为 O(h)=O(log<sub>d</sub>N)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。

    * （二）利用磁盘预读特性
        * 为了减少磁盘 I/O，磁盘往往不是严格按需读取，而是每次都会预读。
            * 预读的理论依据：局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。
            * 预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的旋转时间，速度会非常快。
        * 数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。
            * 操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。
### 1）. B+Tree 索引

#### 1.1 是大多数 MySQL 存储引擎的默认索引类型。

#### 1.2 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。

#### 1.3 除了用于查找，还可以用于排序和分组。
#### 1.4 可以指定多个列作为索引列，多个索引列共同组成键。但存在限制
##### 限制：B+ 树索引适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。
* 所以索引列顺序很重要，在优化性能的时候，可能需要使用相同的列，但顺序不同的索引来满足不同的需要。

#### 1.5 InnoDB 的 B+Tree 索引分为主索引和辅助索引。
##### 1.5.1 主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。

![](https://github.com/CyC2018/CS-Notes/raw/master/pics/c28c6fbc-2bc1-47d9-9b2e-cf3d4034f877.jpg)

##### 1.5.2 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。
* 辅助索引的叶子结点获得对应的主键值而非行指针，这样的策略减少了当行出现移动或者数据分裂时二级索引的维护工作。

![](https://github.com/CyC2018/CS-Notes/raw/master/pics/7ab8ca28-2a41-4adf-9502-cc0a21e63b51.jpg)
#### 1.6 附录：聚簇索引：并不是一种索引类型，而是一种数据存储方式
* 1、InnoDB 通过主键聚集数据，如果没有定义主键，InnoDB 会选择一个唯一的非空索引代替，如果没有这样的索引，InnoDB 会隐式地定义一个主键来作为聚簇索引。
* 2、聚簇索引的优点：
    * 1）可以把相关数据保存在一起，减少了I/O
    * 2）数据访问更快（因为聚簇索引将索引和数据保存在一个B+树中）
    * 3）使用覆盖索引扫描查询可以直接使用页节点中的主键值。
* 3、聚簇索引的缺点：163
* 4、InnoDB 中聚簇索引的每个叶子节点都包含了主键值、事务ID 、用于事务和MVCC 的回滚指针，以及所有的剩余列。【MyISAM 是非聚簇索引，它的主键索引和其他索引并没有什么不同】

### 2. 哈希索引：【用的hash表，先使用索引列的全部内容来计算哈希值，然后用该值寻找对应的记录的指针】
#### 2.1 哈希索引的优缺点：哈希索引能以 O(1) 时间进行查找，但是失去了有序性：
##### 1）无法用于排序与分组；
##### 2）只支持精确查找，无法用于部分查找和范围查找。

#### 2.2 自适应哈希索引：InnoDB 存储引擎的一个特殊的功能。，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。
#### 2.3 自定义哈希索引：在B+树基础上创建一个伪哈希索引，它还是使用B+树进行查找，但使用的是哈希值而不是键本身进行索引查找。【应用：当需要存大量URL的时候，此时只需要根据哈希值做快速的整数比较就能找到索引条目，而用URL值比较会很慢
】

### 3. 全文索引：MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。

* 查找条件使用 MATCH AGAINST，而不是普通的 WHERE。

* 全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。

* InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。

### 4. 空间数据索引

MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。

必须使用 GIS 相关的函数来维护数据。

## 2.2 索引的优点：
### 1）大大减少了服务器需要扫描的数据行数
### 2）帮助服务器避免进行排序和创建临时表（B+树索引是有序的，可以用来做ORDER BY 和GROUP BY操作）
### 3）将随机I/O变为顺序I/O（B+树索引是有序的，也就是相邻的数据都存储在一起了）
## 2.3 MySQL有两种方式可以生成有序的结果：通过排序操作、通过索引顺序扫描【 explain 出来的 type 为 “index” 表示按索引顺序扫描】

## 2.4 索引优化

### 1. 多列索引：在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。
* 例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。

```sql
SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
```

### 2. 索引列的顺序：让选择性最强的索引列放在前面。

* 索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，查询效率也越高。

* 例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。

```sql
SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,
COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,
COUNT(*)
FROM payment;
```

```html
   staff_id_selectivity: 0.0001
customer_id_selectivity: 0.0373
               COUNT(*): 16049
```

### 3. 前缀索引：对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。

* 对于前缀长度的选取需要根据索引选择性来确定。
* 可以在一个查询中针对不同前缀长度的选择性进行计算，这对于大表非常有用，下面给出如何在同一个查询中计算不同前缀长度的选择性：
```sql
mysql> select count(distinct left(city,3))/count(*) as sel3,
    -> count(distinct left(city,4))/count(*) as sel4,
    -> count(distinct left(city,5))/count(*) as sel5, 
    -> count(distinct left(city,6))/count(*) as sel6 
    -> from city_demo;
+--------+--------+--------+--------+
| sel3   | sel4   | sel5   | sel6   |
+--------+--------+--------+--------+
| 0.3367 | 0.4075 | 0.4208 | 0.4267 |
+--------+--------+--------+--------+
1 row in set (0.01 sec)

mysql> 
```
可以看见当索引前缀为6时的基数是0.4267，已经接近完整列选择性0.4283。

在上面的示例中，已经找到了合适的前缀长度，下面创建前缀索引：
```sql
mysql> alter table city_demo add key (city(6));
Query OK, 0 rows affected (0.19 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql> 

mysql> explain select * from city_demo where city like 'Jinch%';
+----+-------------+-----------+-------+---------------+------+---------+------+------+-------------+
| id | select_type | table     | type  | possible_keys | key  | key_len | ref  | rows | Extra       |
+----+-------------+-----------+-------+---------------+------+---------+------+------+-------------+
|  1 | SIMPLE      | city_demo | range | city          | city | 20      | NULL |    2 | Using where |
+----+-------------+-----------+-------+---------------+------+---------+------+------+-------------+
1 row in set (0.00 sec)
```

### 4.使用覆盖索引：索引包含所有需要查询的字段的值。

#### 4.1 覆盖查询的优点：

##### 1）索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
##### 2）一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
##### 3）对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。
##### 4）因为索引是按照列值顺序存储的（至少在单个页内是如此），所以对于I/O密集型的范围查询会比随机从磁盘读取一行数据的I/O要少得多。

## 2.5 注意： 
### 1） 独立的列：在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。

* 例如下面的查询不能使用 actor_id 列的索引：

```sql
SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;
```
### 2）在InnoDB 表中按主键顺序插入行：如果正在使用InnoDB 表并且没有什么数据需要聚集，那么可以定义一个AUTO_INCREAMENT自增列作为主键，这样可以保证数据行是按顺序插入的。
* 那么InnoDB 就可以把每一条记录都存储在上一条记录的后面，当页达到最大填充因子时（默认是页大小的15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。数据按照这种顺序的方式加载，主键页就会近似于被顺序的记录填满。

# 三、查询性能优化【要合理设计查询，查询优化、索引优化、库表结构优化需要齐头并进】

## 3.1 使用 Explain 进行分析：开发人员可以通过分析 Explain 结果来优化查询语句。

Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

比较重要的字段有：【衡量查询开销的三个指标：响应时间、扫描的行数、返回的行数】

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

## 3.2 优化数据访问

### 1. 减少请求的数据量：【让查询只返回需要的数据】
#### 1.1 只返回必要的列【最好不要使用 SELECT * 语句。】
* 取出所有的列，会让优化器无法完成索引覆盖扫描这类优化，还会为服务器带来额外的I/O，内存和CPU消耗
#### 1.2 只返回必要的行【使用 LIMIT 语句来限制返回的数据。】
* 不加上limit的后果是MySQL会查询出全部的结果集，客户端应用程序接收全部的结果集数据，然后抛弃其中大部分数据。
#### 1.3 缓存重复查询的数据
* 使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。

### 2. 减少服务器端扫描的行数

#### 2.1 最有效的方式是使用索引来覆盖查询。
* 使用索引覆盖扫描，把所有需要用到的列都放在索引中，这样存储引擎无需返回表获取对应的行就可以返回结果了。
#### 2.2 重写这个复杂的查询

## 3.3 重构查询方式

### 1. 切分大查询：一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

```sql
DELETE FROM messages WHERE create < DATE_SUB(NOW(), INTERVAL 3 MONTH);
```

```sql
rows_affected = 0
do {
    rows_affected = do_query(
    "DELETE FROM messages WHERE create  < DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000")
} while rows_affected > 0
```

### 2. 分解关联查询：将一个关联查询（join）分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：

- 1）让缓存更高效。
    * 对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
- 2）分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
- 3）减少锁竞争；
    * 查询分解后，执行单个查询可以减少锁竞争
- 4）在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
- 5）查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。

```sql
SELECT * FROM tab
JOIN tag_post ON tag_post.tag_id=tag.id
JOIN post ON tag_post.post_id=post.id
WHERE tag.tag='mysql';
```

```sql
SELECT * FROM tag WHERE tag='mysql';
SELECT * FROM tag_post WHERE tag_id=1234;
SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);
```
- 6）可以减少冗余记录的查询。
    * 在应用层做关联查询，意味着对于某条记录应用只需要查询一次，而在数据中做关联查询，则可能需要重复地访问一部分数据。
# 四、切分：【分表：把一张表按照一定的规则分解成不同的实体表】

## 4.1 水平切分：又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。

* 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。
### 4.1.1  Sharding 策略

#### 1) 哈希取模：hash(key) 模 N；
#### 2) 范围：可以是 ID 范围也可以是时间范围；
#### 3) 映射表：使用单独的一个数据库来存储映射关系。

### 4.1.2 Sharding 存在的问题

#### 1). 事务问题（分片事务一致性难以解决）：使用分布式事务来解决，比如 XA 接口。

#### 2). JOIN问题【跨界点JOIN性能差，逻辑复杂】：可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。

#### 3）. ID 唯一性问题：

##### 3.1 使用全局唯一 ID（GUID）
##### 3.2 为每个分片指定一个 ID 范围
##### 3.3 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)
![]
(https://github.com/CyC2018/CS-Notes/raw/master/pics/63c2909f-0c5f-496f-9fe5-ee9176b31aba.jpg)
## 垂直切分：是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。

* 在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。

![](https://github.com/CyC2018/CS-Notes/raw/master/pics/e130e5b8-b19a-4f1e-b860-223040525cf6.jpg)



# 五、复制：MySQL支持两种复制方式：基于行的复制和基于语句的复制（逻辑复制）
## 5.1 复制解决的基本问题是让一台服务器的数据和其他服务器保持同步：一台主库的数据可以同步到多台备库上。
## 5.2 什么是主从复制：主从复制是用来建立一个和主数据库完全一样的数据库环境，成为从数据库；主数据库一般是准实时的业务数据库。
## 5.3 主从复制主要涉及三个线程：：binlog 线程、I/O 线程和 SQL 线程。
![](https://images2017.cnblogs.com/blog/1228077/201712/1228077-20171222172536490-502075237.png)
### 步骤一：主库db的更新事件(update、insert、delete)被写到binlog【二进制日志】

### 步骤二：从库发起连接，连接到主库

### 步骤三：此时主库创建一个binlog dump 线程，把binlog的内容发送到从库

### 步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log【重做日志】.

### 步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db.

可以知道，对于每一个主从复制的连接，都有三个线程。拥有多个从库的主库为每一个连接到主库的从库创建一个binlog输出线程，每一个从库都有它自己的I/O线程和SQL线程。

## 5.3 主从复制的好处：
### 1）作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作。
### 2) 架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能
### 3）读写分离：主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。

读写分离能提高性能的原因在于：

- 主从服务器负责各自的读和写，极大程度缓解了锁的争用；
- 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；
- 增加冗余，提高可用性。

读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。



# 六、数据类型

## 6.1 整型：NT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。

TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。


## 6.2 浮点数：DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。

FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。
## 6.3 字符串：主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。

VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。

在进行存储和检索时，会保留 VARCHAR 末尾的空格，而会删除 CHAR 末尾的空格。

## 6.4 时间和日期：DATETIME 和 TIMESTAMP。

MySQL 提供了两种相似的日期时间类型：DATETIME 和 TIMESTAMP。

### 1. DATETIME：能够保存从 1001 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。【它与时区无关。】

默认情况下，MySQL 以一种可排序的、无歧义的格式显示 DATETIME 值，例如“2008-01-16 22:37:08”，这是 ANSI 标准定义的日期和时间表示方法。

### 2. TIMESTAMP：和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。【它和时区有关】
* 也就是说一个时间戳在不同的时区所代表的具体时间是不同的。

MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳。

默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。

应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。

# 七、视图
## 1、视图本身是一个虚拟表，在创建的瞬间，便确定了结构（每次查询视图，实际还是去查询原来的表）
## 2、视图的算法（Algotithm）有三种：
### 2.1 undefined：【默认方式】，由MySQL判断使用哪种算法
### 2.2 merge：【合并算法】，每当执行的时候，先将视图的sql语句于外部查询视图的sql语句合并在一起最终执行。
* create algorithm = merge view as select * from t1;
### 2.3 temptable：【临时表算法】，每当查询的时候，将视图的sql语句生成一个结果的临时表，再在临时表内进行查询
## 3、注意：如果视图包含group by、distinct、任何聚合函数、union、子查询等，只要无法在原表记录和视图记录建立一一映射的场景中，MySQL都将使用临时表算法来实现视图

# 八、外键约束
## 1、InnoDB 是目前MySQL中唯一支持外键的内置存储引擎。
* 使用外键是有成本的：外键通常都要求每次在修改数据时都要在另一张表中多执行一次查找操作。
* InnoDB 强制外键使用索引

# 九、分布式（XA）事务
## 1、存储引擎的事务特性能保证在存储引擎级别实现ACID
## 2、而分布式事务让存储引擎级别的ACID 可以扩展到数据库层面（跨存储引擎的事务），甚至可以扩展到多个数据库应用之间。
## 3、XA 事务需要通过两个阶段的提交来实现：
### 3.1 第一阶段：XA事务中需要有一个事务协调器来保证所有的事务参与者都完成了准备工作。
### 3.2 第二阶段：如果协调者收到所有参与者都准备好的消息，就会告诉所有的事务可以提交了。
## 4、XA 事务分为：
### 1）内部XA事务：MySQL本身的插件式架构导致其在内部需要使用XA事务
* 一个跨存储引擎的事务就需要一个外部的协调者
### 2）外部XA事务：MySQL可以参与到外部的分布式事务中

# 十、分区表
## 1、分区表：是一个独立的逻辑表，底层由多个物理子表组成。
* 实现分区的代码实际上是对一组底层表的句柄对象的封装。对分区表的请求，都会通过句柄对象转化为对存储引擎的接口的调用
## 2、分区表的原理：所有底层表都必须使用相同的存储引擎，分区表的索引只是在各底层表上各自加上一个完全相同的索引
* select、update、insert、delete操作都会“先打开并锁住所有的底层表”，但分区表在处理过程中并不是锁住全表的，比如InnoDB 会在分区层释放对应的表锁，用行级锁。
## 3、分区的类型
### 1）range分区：将数据划分为不同的范围。（连续）
### 2）list分区：允许系统通过预定义的列表值来对数据进行分割（非连续，按值分区）
### 3）hash分区：主要用来确保数据在预先确定数目的分区中平均分布。
create table t1(...)
partition by hash(id)
partitions 4;  //你只需要指定多少个分区，其余MySQL会做
### 4）key分区：类似hash分区，只是hash分区使用的是用户自定义的表达式（hash）,而key分区使用的哈希函数是由MySQL服务器提供的。
## 4、优化查询：
### 1）在查询时，要在where条件中代入分区列，即使看似多余也要带上，这样就可以让优化器能够过滤掉无需访问的分区
### 2）如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会缓存在内存中，查询时只访问很小的一个分区表，能够有效地利用索引和缓存。
## 5、分区的优缺点：
### 5.1 分区的优点：
#### 1）可以让单表存储更多的数据
#### 2）分区表的数据更易维护，可以清除整个分区批量删除数据，还可以对一个独立分区进行优化、检查、修复等操作
#### 3）部分查询能够从查询条件确定只落在少数分区上，速度会很快
#### 4）分区表的数据还可以分布在不同的物理设备上，从而高效利用多个硬件设备
#### 5）可以备份和恢复整个分区
### 5.2 分区的缺点：
#### 1）一个表最多只能有1024个分区
#### 2）如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来
#### 3）分区表中无法使用外键约束

# 十一、MySQL大表优化方案
## 1）优化数据访问【前面】
## 2）升级硬件：通过提升CPU和内存、使用ssd，都能显著提升MySQL的性能
## 3）读写分离：主库用来处理写操作和实时性较高的读操作，从库用来处理写操作
## 4）用缓存：使用MySQL的缓存，另外对重量级、更新少的数据考虑使用应用级别的缓存
* 缓存可以发生在这些层次：
    * MySQL内部
    * 数据访问层：mybatis针对sql语句做缓存
    * 应用服务层：缓存的是数据传输对象
    * web层：针对web页面做缓存
    * 浏览器客户端：用户端的缓存
## 5）使用分区表：分区表是一个独立的逻辑表，底层由多个物理子表构成
### 5.1 在查询时，要在where条件中代入分区列，即使看似多余也要带上，这样就可以让优化器能够过滤掉无需访问的分区
### 5.2 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会缓存在内存中，查询时只访问很小的一个分区
## 6）进行分表：把一张表按照一定的规则分成不同的实体表
### 6.1 垂直拆分：将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以按经常使用和不经常使用来切分。
#### 6.1.1 优点：
##### 1）使行数据变小，一个数据块（页）能存放更多的数据，从而在查询时减少I/O次数
##### 2）简化表结构，易于维护
#### 6.1.2 缺点：
##### 1）主键出现冗余，需要管理冗余列
##### 2）会引起join操作，可以通过在应用层进行join来减少服务器压力
##### 3）事务变得更复杂，且还是存在单表数据量过大的问题（需要水平拆分）
### 6.2 水平拆分：将用一个表中的记录拆分到多个结构相同的表中。当一个表中的数据不断增多时，水平拆分是必然的选择，它可以将数据分步到集群的不同节点上，从而缓解单个数据库的压力。

# 十二 杂
## 1 死锁
### 1.1 检测：InnoDB 存储引擎，能检测到死锁的循环依赖，并返回一个错误。
* 数据库系统实现了各种死锁检测和死锁超时的机制。
### 1.2 死锁解决：InnoDB 处理死锁是将持有最少行级排他锁的事务进行回滚。
* 其他方式：当查询的时间到达锁等待超时的设定后放弃锁请求。
* 应用程序设计时考虑死锁的处理方法：大多数情况下只需要重新执行因死锁回滚的事务即可。
* 死锁产生的原因：
    * 1）因为真正的数据冲突，通常难以避免
    * 2）因为存储引擎的实现方式导致。
## 2 事务日志：可以提高事务的效率
### 1）使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘
### 2）事务日志采用的是追加的方式，因此写日志的操作是磁盘上小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说快得多
### 3）事务日志持久以后，内存中被修改的数据在后台可以慢慢刷回磁盘，也叫预写式日志，所以修改数据需要写两次磁盘。
## 3 冗余索引和重复索引
### 3.1 重复索引：指在相同的列上按照相同的顺序创建相同类型的索引（发现后应该立即移除）
``` mysql
create table test(id primary key,
unique(id),
index(id));  //三个重复索引
```
### 3.2 冗余索引：通常发生在为表添加新索引的时候，如创建了索引（A,B），再创建索引（A）就是冗余索引，因为这只是前一个索引的前缀索引
* 因为表中索引越多插入速度就越慢
* 应该尽量扩展已有的索引而不是创建新索引。但有时因为扩展已有的索引会导致其变得太大，从而影响其他使用该索引的查询的性能，就需要考虑冗余索引
### 3.3 编写查询语句应该尽可能选择合适的索引以避免单行查找，尽可能使用数据原生顺序从而避免额外的排序操作。



# 参考资料

- BaronScbwartz, PeterZaitsev, VadimTkacbenko, 等. 高性能 MySQL[M]. 电子工业出版社, 2013.
- 姜承尧. MySQL 技术内幕: InnoDB 存储引擎 [M]. 机械工业出版社, 2011.
- [20+ 条 MySQL 性能优化的最佳经验](https://www.jfox.info/20-tiao-mysql-xing-nen-you-hua-de-zui-jia-jing-yan.html)
- [服务端指南 数据存储篇 | MySQL（09） 分库与分表带来的分布式困境与应对之策](http://blog.720ui.com/2017/mysql_core_09_multi_db_table2/ "服务端指南 数据存储篇 | MySQL（09） 分库与分表带来的分布式困境与应对之策")
- [How to create unique row ID in sharded databases?](https://stackoverflow.com/questions/788829/how-to-create-unique-row-id-in-sharded-databases)
- [SQL Azure Federation – Introduction](http://geekswithblogs.net/shaunxu/archive/2012/01/07/sql-azure-federation-ndash-introduction.aspx "Title of this entry.")
- [MySQL 索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)
- [MySQL 性能优化神器 Explain 使用分析](https://segmentfault.com/a/1190000008131735)
- [How Sharding Works](https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6)
- [大众点评订单系统分库分表实践](https://tech.meituan.com/dianping_order_db_sharding.html)
